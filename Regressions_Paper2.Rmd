---
title: "Regressions Paper II"
output:
  pdf_document:
    toc: no
  html_document:
    code_folding: hide
    dev: png
    highlight: tango
    self_contained: yes
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
header-includes:
- \usepackage{dcolumn,rotating, longtable}

---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)


set.seed(12345)
library(tidyverse)
library(stringr)
library(forcats)
library(RColorBrewer)
library(ggplot2)
library(GGally)
library(moments)
library(broom)

library(grid)
library(gridExtra)
library(plm)
library(lmtest)
library(splm)
library(car)
library(estimatr)
library(kableExtra)
```
  
This document explores new regressions for the analysis of game data of Cienaga Grande de Santa Marta. Most ideas were discussed with Jorge Maldonado in our last meeting in Gothemburg. As response variable we use individual extraction in the game, and the proportion of individual extraction / stock size. The results for OLS are presented graphically: simple OLS, robust OLS, and robust OLS with clustered standard errors were fitted. With the aim of replicating STATA output, the variance covariance matrix is calculated with White variance method with weighting scheme "HC1", which is the default in STATA. 
```{r data, warnings = FALSE, message = FALSE, include = FALSE}

### load dataset
## Survey data
source('~/Documents/Projects/BEST - Beijer/BEST/160525_ErrorIdentificationSurvey.R')

#key
key <- read.csv2(file = '~/Dropbox/BEST/Colombia/Survey/key_consolidado_survey.csv', encoding = "Latin-1" )
key <- key [c(1:16,23:240),c(2:5)]
  key$Name.in.datasheet <- as.character(key$Name.in.datasheet)
  levels(key$Data.type)[3] <- "binary"
  key <- droplevels(key)
  key$Column.datasheet <- seq(1:234)

# load game data in long format, short format also available
dat <- read.csv(file="~/Dropbox/BEST/Colombia/0_Game data/160427_corrected_full_data_long.csv", row.names=1)

# Create player ID's as in Surveys.R
dat <- transform(dat, ID_player = interaction(Date, Treatment, Session, Player, drop = TRUE))
# Create ID group
dat <- transform(dat, group = interaction (Date, Treatment, Session, drop=T))
dat <- as_tibble(dat) %>%
  rename(ind_extraction = value)

# reorder levels
dat$Treatment <- factor(dat$Treatment, levels(dat$Treatment)[c(1,3,2,4)])
# levels(dat$Treatment)

dat <- mutate (dat, threshold = ifelse (dat$Treatment == "Base line" | dat$part == FALSE, 20, 28 ))
dat <- dat %>% mutate(
  dummy_threshold = ifelse(NewStockSize - threshold > 0, FALSE, TRUE))

## Use the deviation from threshold, and dev_t_divided by 4
dat <- dat %>%
  mutate (dev_drop = ifelse(dat$Treatment == 'Base line' | dat$part == FALSE,
                                ((dat$IntermediateStockSize - 20)) ,  # - dat$value
                                 ((dat$IntermediateStockSize - 28))   )) #- dat$value
## here cooperation is calculated.
dat <- dat %>%
  mutate (optimal = (StockSizeBegining - threshold) / 4) %>%
  mutate (cooperation = ifelse(
    StockSizeBegining == 0, NA, 
    ifelse((4*optimal) < 0 & ind_extraction == 0, 0, optimal - ind_extraction))) %>%
  mutate(cooperation2 = ifelse(
    optimal < 1 & ind_extraction == 0, 1,
    ifelse(optimal == 0 & ind_extraction == 1, 1.5, 
    ifelse(optimal < 1 & ind_extraction > 0, ind_extraction, ind_extraction / optimal)
  )))

## use the demeaned extraction as a try:
dat <- dat %>%
  mutate(demean_extraction = (ind_extraction - mean(ind_extraction))/ sd(ind_extraction)) %>%
  mutate(stock_ratio = ind_extraction/StockSizeBegining)

## test of normality:
# shapiro.test(dat$cooperation2)
# interpretation: if p > 0.05 then is normal, if not, it's not normally distributed.


## coordination is calculated next

dist_group <- function(x){ # x will be the character identifier for each player
  y <- dat %>% select(ID_player, Round, ind_extraction, group) %>%
    filter(group == substr(x,start = 1, stop = nchar(x) - 2)) %>% # filter per group based on ID_player
    select(-group) %>% spread(Round, ind_extraction)
  z <- vegan::vegdist(y[-1], "bray") # Bray-curtis is bounded 0:1 with zero absolute similarity and 1 complete different
  player <- substr(x, start = nchar(x), stop = nchar(x)) # the player is the last number of the string
  mean_dist <- colSums(as.matrix(z))[as.numeric(player)] / 3 # divided by the other 3 players. Note the dist to self is 0
  df <- data_frame(ID_player = x, mean_dist = mean_dist)
  return(df)
}

x <- lapply(levels(dat$ID_player), dist_group)
x <- bind_rows(x)
x$ID_player <- as.factor(x$ID_player)
x <- mutate(x, coordination = 1-mean_dist)



### For the analysis proposed by Jorge I need to get rid of missing values, set all NA to zero before calculating anything else.
dat <-  dat %>%
  replace_na(list(StockSizeBegining = 0, SumTotalCatch = 0, IntermediateStockSize = 0, Regeneration = 0, NewStockSize = 0))



# rm(y , z, player, mean_dist, df)

ind_coop <- dat %>% filter(part == TRUE) %>%
  select( Treatment, Place, ID_player, group, Round, cooperation2, part, Player) %>%
  group_by(Treatment, Place, ID_player, group, part, Player) %>%
  summarize(Cooperation = mean(cooperation2, na.rm = T),
            variance = var(cooperation2, na.rm = T),
            skewness = skewness(cooperation2, na.rm = T),
            med_coop = median(cooperation2, na.rm = T))

exp_notes <- as_tibble(exp_notes)
agreements <- exp_notes %>% 
  select(39,98, A.round, ID_player, ID_Obs) %>% 
  mutate(
    round = as.numeric(A.round), 
    agreement = pmax(A11.3..agreement, B11.3..agreement, na.rm = TRUE)) %>% 
  filter(round>6) %>% 
  group_by(ID_player) %>% 
  summarize(prop_ag = sum(agreement, na.rm = T)/10)


risk_amb <- exp_notes %>% select(119:130,132) %>% unique()

risk <- risk_amb %>% select(13,
    Risk_0_38k = 1, Risk_13k =2, Risk_10_19k = 3,
    Risk_7_25k = 4, Risk_4_31k = 5, Risk_2_36k = 6)

risk <- risk %>%
    mutate(Risk_0_38k = forcats::fct_recode(Risk_0_38k, NULL = '', '1' = '|')) %>% mutate(Risk_0_38k = as.numeric(as.character(Risk_0_38k))) %>%
    gather(key = Risk, value = choice, 2:7, na.rm = FALSE) %>%
    filter(choice == 1)

risk$Risk <- as.factor(risk$Risk)
levels(risk$Risk) <- c(6,2,1,5,4,3)
risk$Risk <- as.numeric(risk$Risk)

# J190219: Note that there are few people with no choice in the risk task. So one looses something here (7obs), need to go back to original data.

### J180102: There is errors also on the ambiguity elicitation task data. The group of 2016-02-09.Threshold.am all players have NAs.
amb <- risk_amb %>% select(13, Amb_0_38k = 7, Amb_13k =8, Amb_10_19k = 9, Amb_7_25k = 10, Amb_4_31k = 11, Amb_2_36k = 12)

## for the people with two choices, I leave only one manually, but note, this needs to be checked with raw data and change afterwards here to correct for the right one.
# this command shows the errors:
# amb %>% group_by(ID_player) %>% summarize(choice = sum(Amb_0_38k, Amb_13k, Amb_10_19k, Amb_7_25k ,Amb_4_31k ,Amb_2_36k)) %>% filter(choice == 0 | choice == 2 | is.na(choice))
## Manual corrections
amb[amb$ID_player == "2016-02-01.Threshold.am.2", "Amb_4_31k"] <- 0
amb[amb$ID_player == "2016-02-05.Uncertainty.am.2", "Amb_10_19k"] <- 0
amb[amb$ID_player == "2016-02-02.Base line.am.4", "Amb_10_19k"] <- 1

## note, this still keeps the NA players and they are dropped when choice == 1, but at least there is no duplicates now.
## The dataset still only has 252/256 obs, for 4 people all choices were coded as zero.
amb <- amb %>%
  gather(key = Amb, value = choice, 2:7) %>%
  filter(choice == 1)

amb$Amb <- as.factor(amb$Amb)
levels(amb$Amb) <- c(6,2,1,5,4,3)
amb$Amb <- as.numeric(amb$Amb)

ind_coop <- left_join(ind_coop, surv, by = "ID_player") %>%  ## Now drop the columns that are not useful for now in the regression
  select( c(1:21, life_satisfaction = 29, EE_before = 30, partner_in_group = 31,
            fishing_age=35,fishing_last_yr = 39, week_days = 53, ND_hrs = 54, ND_kg = 55, ND_pesos =56,
            BD_kg = 59, BD_pesos = 60, BD_how_often = 61, group_fishing = 62, boat = 68,
            take_home= 94, sale= 95, give_away = 97,
            fishing_future = 98, fishing_children=100, history_rs = 106,  sharing_art=147,
            belongs_coop=149, age=167, education = 168, education_yrs=169 ))

ind_coop$BD_how_often[is.na(ind_coop$BD_how_often)] <- 0

ind_coop$ID_player <- as.character(ind_coop$ID_player)
risk$ID_player <- as.character(risk$ID_player)
amb$ID_player <- as.character(amb$ID_player)
x$ID_player <- as.character(x$ID_player)

ind_coop <- left_join(ind_coop, x, by = "ID_player")

ind_coop <- left_join(ind_coop, select(risk, 1,2), by = "ID_player")


### here is the error now
ind_coop <- left_join(ind_coop, select(amb, 1,2), by = "ID_player")

## log-transform money related variables

ind_coop <- mutate(ind_coop, ND_log_pesos = log(ND_pesos), BD_log_pesos = log1p(BD_pesos))

ind_coop <- dat %>%
  group_by(ID_player, part) %>%
  summarize(
    mean_extraction = mean(ind_extraction, na.rm = TRUE),
    mean_prop_extr = mean(stock_ratio, na.rm = TRUE),
    var_extraction = var(ind_extraction, na.rm = TRUE),
    var_prop_extr = var(stock_ratio, na.rm = TRUE)
  ) %>%
  right_join(ind_coop)

## correct education, there is two variables with the same info, unify to avoid missing values:

ind_coop <- ind_coop %>%
  mutate(education_yr = ifelse(
    !is.na(education_yrs), education_yrs,
    ifelse(
      education == 1, 0,
      ifelse(
        education == 2, 5, 
        ifelse(education == 3, 11, 16)
      )
    )
  ))

ind_coop <- ind_coop %>% 
  left_join(agreements)

## correct fishing_children:

ind_coop <- ind_coop %>%
  mutate(
    fishing_children = ifelse(
      is.na(fishing_children), 0,
      ifelse(
        (fishing_children < 2 | fishing_children == 4), 0, 1
        )
    )
  ) 


# 
# surv %>%
#   select(grop_fishing_partner = 21, fishing_group = 52, art = 64, fishing_future=88, 
#          same_spp = 92, dramatic_changes = 96, share_art = 137, coop = 139) %>%
#   mutate(art = as.character(art)) %>%
#   skimr::skim()
#   pull(coop) %>% unique()

```

## OLS
### OLS estimation: individual extraction & proportion of stock

```{r include = FALSE}
# names(dat)
```

```{r include = FALSE}
ols <- lm(ind_extraction ~ Treatment + part + as.numeric(Round) + StockSizeBegining , 
           data = dat)
# summary(ols)

# stargazer::stargazer(ols)
# ols %>% tidy() %>%
#   kable()
```

```{r include = FALSE}
ols_robust <- lm_robust(
  ind_extraction ~ Treatment + part  + as.numeric(Round) + StockSizeBegining ,
  data = dat, se_type = "stata")
# summary(ols_robust)

## comparison with base
# coeftest(ols, vcov = vcovHC(ols, type = "HC1"))
```

```{r include = FALSE}
ols_robust_cluster <- lm_robust(
  ind_extraction ~ Treatment + part + as.numeric(Round) + StockSizeBegining ,
  cluster = group,
  data = dat, se_type = 'stata')
# summary(ols_robust_cluster)
```


```{r fig1, fig.height= 3, fig.width= 6, include = TRUE, echo = FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.cap = 'Comparison of linear models. (A) individual extraction and (B) proportion of stock available as response variable. SE estimation using HC1 (Stata default) and are clustered around groups.', fig.pos = "h"}
df1 <- tidy(ols) %>% mutate(model = "ols")
df2 <- tidy(ols_robust) %>% mutate(model = "ols robust")
df3 <- tidy(ols_robust_cluster) %>% mutate(model = "ols robust \n cluster SE")

df_A <- bind_rows(df3,df2 ,df1)

# g1 <- df %>% 
#   mutate(term = factor(term, levels = rev(unique(term)))) %>%
#   ggplot(aes(x = estimate, y = term)) +
#   geom_vline(xintercept = 0, color = "grey84", linetype = 2, size = 0.5) +
#     geom_point(aes(shape = ifelse(
#         p.value < 0.05, "< 0.05" ,
#             ifelse(p.value < 0.1, "< 0.1", "> 0.1")
#         )), size = 2, show.legend = TRUE) +
#     scale_shape_manual(name = "p value", values = c(19,7,1)) +
#     geom_errorbarh(aes(xmin = conf.low, xmax = conf.high, height = .25)) +
#   facet_grid(. ~ model, scales = "free_x") +
#   theme_light(base_size = 7) + theme(legend.position = "bottom") +
#   labs(tag = "A")


#### With proportion
dat <- dat %>% mutate(prop = ind_extraction/StockSizeBegining)
ols <- lm(prop ~ Treatment + part + as.numeric(Round)  , 
           data = dat)
# summary(ols)
# robust
ols_robust <- lm_robust(
  prop ~ Treatment + part  + as.numeric(Round),
  data = dat, se_type = "stata")
#summary(ols_robust)

## comparison with base
#coeftest(ols, vcov = vcovHC(ols, type = "HC1"))

# clustered
ols_robust_cluster <- lm_robust(
  prop ~ Treatment + part + as.numeric(Round),
  cluster = group,
  data = dat, se_type = 'stata')
# summary(ols_robust_cluster)

df1 <- tidy(ols) %>% mutate(model = "ols")
df2 <- tidy(ols_robust) %>% mutate(model = "ols robust")
df3 <- tidy(ols_robust_cluster) %>% mutate(model = "ols robust \n cluster SE")

df_B <- bind_rows(df3,df2 ,df1)

df_A$response <- "ind extraction"
df_B$response <- "proportion stock"

df <- bind_rows(df_A, df_B)


g2 <- df %>% 
  mutate(term = factor(term, levels = rev(unique(term)))) %>%
  ggplot(aes(x = estimate, y = term)) +
  geom_vline(xintercept = 0, color = "grey84", linetype = 2, size = 0.5) +
    geom_point(aes(shape = ifelse(
        p.value < 0.05, "< 0.05" ,
            ifelse(p.value < 0.1, "< 0.1", "> 0.1")
        )), size = 2, show.legend = TRUE) +
    scale_shape_manual(name = "p value", values = c(19,7,1)) +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high, height = .25)) +
  facet_grid(. ~ response + model, scales = "free_x") +
  theme_light(base_size = 7) + theme(legend.position = "bottom") 

# source('~/Dropbox/Code/multiplot.R')
# g <- list (g1,g2 )
# 
# layout <- matrix(c(1:2), ncol = 2, nrow = 1, byrow = T)
# multiplot(plotlist = g, layout = layout)

g2
```



## Panels
### Panel estimation: individual extraction & proportion of stock size

The results for panel models are presented in regression tables, Table 1 shows results for individual extraction as response variable, while Table 2 shows the equivalent for proportion of stock size. Model specification are as follows:

* Simple panels:
    1. Simple panel 
    2. Robust panel
    3. Robust and clustered panel (I found a way to cluster around 3 dimensions!)
* Interaction terms:
    4. Simple panel with interaction terms
    5. Robust panel with interaction terms
    6. Robust and clustered panel with interaction terms
* Only fase 2:
    7. Panel with only fase 2 of the game
    8. Robust panel with only fase 2 of the game
    9. Robust and clustered panel with only fase 2 of the game
* Extra [**J190213:** expanded on next section entitled Diff-in-diff]:
    10. The model I trust the most is (6), it's the diff-in-diff approach clustered in three dimensions (individual, time, group). Model 10 calculate the clustered standard errors with Nwewy and West (1987) robust covariance matrix estimator, which I read is more appropriate for dynamic games with short panels. Other sources also propose the type "HC4" as more reliable (more restrictive).



```{r include = FALSE}
# simple
p1 <- plm(ind_extraction ~ Treatment + part + as.numeric(Round) + StockSizeBegining , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )
# robust: # I think white1 and HC1 are stata defaults
# coeftest(p1, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
p2 <- plm(ind_extraction ~ Treatment + part + as.numeric(Round) + StockSizeBegining , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p2, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

# summary(p1)
```

```{r include = FALSE}
# simple
p3 <- plm(ind_extraction ~ Treatment + part + Treatment * part + as.numeric(Round) + StockSizeBegining , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )

# robust: # I think white1 and HC1 are stata defaults
# coeftest(p3, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
p4 <- plm(ind_extraction ~ Treatment + part +Treatment * part + as.numeric(Round) + StockSizeBegining , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
# coeftest(p4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))
```

```{r include = FALSE}
# simple
p5 <- plm(ind_extraction ~ Treatment + as.numeric(Round) + StockSizeBegining , 
          data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )

# robust: # I think white1 and HC1 are stata defaults
# coeftest(p5, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
p6 <- plm(ind_extraction ~ Treatment + as.numeric(Round) + StockSizeBegining , 
            data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p6, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
# coeftest(p6, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))
```

```{r include = FALSE}
# simple
q1 <- plm(prop ~ Treatment + part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )
# robust: # I think white1 and HC1 are stata defaults
# coeftest(p1, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
q2 <- plm(prop ~ Treatment + part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p2, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

# summary(p1)

# simple
q3 <- plm(prop ~ Treatment + part + Treatment * part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "individual" )
# summary(p3)
# robust: # I think white1 and HC1 are stata defaults
# coeftest(p3, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
q4 <- plm(prop ~ Treatment + part +Treatment * part + as.numeric(Round) , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
# coeftest(p4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))

# simple
q5 <- plm(prop ~ Treatment + as.numeric(Round) , 
            data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )

# robust: # I think white1 and HC1 are stata defaults
# coeftest(p5, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
q6 <- plm(prop ~ Treatment + as.numeric(Round)  , 
            data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p6, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
#coeftest(p6, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))
```


```{r just_a_try, include = FALSE}
# simple
c1 <- plm(cooperation2 ~ Treatment + part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )
# robust: # I think white1 and HC1 are stata defaults
# coeftest(p1, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
c2 <- plm(cooperation2 ~ Treatment + part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p2, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

# summary(p1)

# simple
c3 <- plm(cooperation2 ~ Treatment + part + Treatment * part + as.numeric(Round)  , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "individual" )
# summary(p3)
# robust: # I think white1 and HC1 are stata defaults
# coeftest(p3, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
c4 <- plm(cooperation2 ~ Treatment + part +Treatment * part + as.numeric(Round) , 
            data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(c4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
# coeftest(c4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))

# simple
c5 <- plm(cooperation2 ~ Treatment + as.numeric(Round) , 
            data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", 
          effect = "individual" )

# robust: # I think white1 and HC1 are stata defaults
# coeftest(p5, vcov.=function(x) vcovHC(x, method="white1", type="HC1"))

# clustered:
c6 <- plm(cooperation2 ~ Treatment + as.numeric(Round)  , 
            data = pdata.frame(dat %>% filter(part == TRUE), index = c('ID_player' ,'Round', "group")),
          model = "random", random.method = "walhus",
          effect = "nested" )
# coeftest(p6, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))

## Alternatively with vcovNW with HC4 which is more strict
#coeftest(p6, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group"))
```

## Diff-in-diff

I was confused for a while on how to get and interpret the diff-in-diff results. It's intuitive when reading _"Mostly harmless econometrics"_ or online tutorials. But my confusion was whether the interaction term `Treatment*Part` was the diff-in-diff term or not. The following teaching slides [^1]:(http://web.mit.edu/teppei/www/teaching/Keio2016/06dd.pdf) helped me out. On slide 11 and 12 it shows the graphical explanation I'm used to, where you get the before after treatment effects comparision between the control group and treated group. Then the difference searched for is based on a parallel trends assumption. I will reproduce the graphical representation in a moment. Before, I'd like to take notes on what solved the problem (slide 17) that says: Because $G{i}$ groups and $T{i}$ treatments are both binary, the same [graphical] estimator can be calculated via regression: 

$$\hat{Y_i} = \hat{\mu} + \hat{\gamma}G_i + \hat{\delta}T_i + \hat{\tau}G_iT_i$$

Where $\hat{\mu}$, $\hat{\gamma}$, $\hat{\delta}$, and $\hat{\tau}$ are OLS regression estimates. 
Then $\hat{\tau}$ is the diff-in-diff effect (or ATT = average treatment on the treated):

Table 1: Definitions of the difference-in-difference approach

|  Terms         | After ($T_i = 1$) | Before ($T_i = 0$) | After-Before |
|:--------------:|:---------------:|:----------------:|:------------:|
|Treated $G_i = 1$ | $\hat{\mu} + \hat{\gamma}+\hat{\delta}+\hat{\tau}$ | $\hat{\mu} + \hat{\gamma}$ | $\hat{\delta}+\hat{\tau}$  |
|Control $G_i = 0$ | $\hat{\mu} + \hat{\delta}$ | $\hat{\mu}$ | $\hat{\delta}$ |
|Treated-Control | $\hat{\gamma}+\hat{\tau}$ | $\hat{\gamma}$ | $\hat{\tau}$ |


Pluggin-in the numbers but now replacing each treatment:

```{r tables, results='asis', include=TRUE, echo=FALSE, warning=FALSE, message=FALSE }

coeffs <- coef(p4)

diff_df <- data_frame(
  treatment = c("Baseline","Threshold","Risk","Uncertainty", "Threshold-Baseline", "Risk-Baseline", "Uncertainty-Baseline", "Threshold-counter", "Risk-counter", "Uncertainty-counter"),
  after = c(
    sum(coeffs[c(1,5)]), # mu and delta = intercept and partTRUE
    sum(coeffs[c(1,5,2,8)]),
    sum(coeffs[c(1,5,3,9)]),
    sum(coeffs[c(1,5,4,10)]),
    sum(coeffs[c(2,8)]),
    sum(coeffs[c(3,9)]),
    sum(coeffs[c(4,10)]),
    sum(coeffs[c(1,5,2)]),
    sum(coeffs[c(1,5,3)]),
    sum(coeffs[c(1,5,4)])
  ),
  before = c(
    coeffs[1],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)]),
    coeffs[2],
    coeffs[3],
    coeffs[4],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)])
  )
)

diff_df <- diff_df %>%
  mutate(difference = after - before)



## Visualization based on raw data
# dat %>% 
#   group_by(Treatment, part) %>% 
#   summarize(mean_t = mean(ind_extraction))  %>% 
#   ggplot(aes(x = part, y = mean_t)) + 
#   geom_point(aes(color = Treatment)) + 
#   geom_line(aes(group = Treatment, color = Treatment))

## Proportion of stock

coeffs <- coef(q4)

diff_df2 <- data_frame(
  treatment = c("Baseline","Threshold","Risk","Uncertainty", "Threshold-Baseline", "Risk-Baseline", "Uncertainty-Baseline","Threshold-counter", "Risk-counter", "Uncertainty-counter" ),
  after = c(
    sum(coeffs[c(1,5)]), # mu and delta = intercept and partTRUE
    sum(coeffs[c(1,5,2,7)]),
    sum(coeffs[c(1,5,3,8)]),
    sum(coeffs[c(1,5,4,9)]),
    sum(coeffs[c(2,7)]),
    sum(coeffs[c(3,8)]),
    sum(coeffs[c(4,9)]),
    sum(coeffs[c(1,5,2)]),
    sum(coeffs[c(1,5,3)]),
    sum(coeffs[c(1,5,4)])
  ),
  before = c(
    coeffs[1],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)]),
    coeffs[2],
    coeffs[3],
    coeffs[4],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)])
  )
)

diff_df2 <- diff_df2 %>%
  mutate(difference = after - before)


## Cooperation

coeffs <- coef(c4)

diff_df3 <- data_frame(
  treatment = c("Baseline","Threshold","Risk","Uncertainty", "Threshold-Baseline", "Risk-Baseline", "Uncertainty-Baseline","Threshold-counter", "Risk-counter", "Uncertainty-counter" ),
  after = c(
    sum(coeffs[c(1,5)]), # mu and delta = intercept and partTRUE
    sum(coeffs[c(1,5,2,7)]),
    sum(coeffs[c(1,5,3,8)]),
    sum(coeffs[c(1,5,4,9)]),
    sum(coeffs[c(2,7)]),
    sum(coeffs[c(3,8)]),
    sum(coeffs[c(4,9)]),
    sum(coeffs[c(1,5,2)]),
    sum(coeffs[c(1,5,3)]),
    sum(coeffs[c(1,5,4)])
  ),
  before = c(
    coeffs[1],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)]),
    coeffs[2],
    coeffs[3],
    coeffs[4],
    sum(coeffs[c(1,2)]),
    sum(coeffs[c(1,3)]),
    sum(coeffs[c(1,4)])
  )
)

diff_df3 <- diff_df3 %>%
  mutate(difference = after - before)

## Visualization based on raw data
# dat %>% 
#   group_by(Treatment, part) %>% 
#   summarize(mean_t = mean(ind_extraction))  %>% 
#   ggplot(aes(x = part, y = mean_t)) + 
#   geom_point(aes(color = Treatment)) + 
#   geom_line(aes(group = Treatment, color = Treatment))

### See first the tables

# stargazer::stargazer(
#   diff_df %>% as.data.frame(), 
#   type = "latex", header = FALSE, summary = FALSE, float = TRUE,
#   digits = 2, title = "Diff-in-diff table for individual extraction")
# 
# stargazer::stargazer(
#   diff_df2 %>% as.data.frame(),
#   type = "latex", header = FALSE, summary = FALSE, float = TRUE,
#   digits = 2, title = "Diff-in-diff table for proportion of stock")
# 
# stargazer::stargazer(
#   diff_df3 %>% as.data.frame(),
#   type = "latex", header = FALSE, summary = FALSE, float =TRUE,
#   digits = 2, title = "Diff-in-diff table for cooperation")

```



```{r fig3, include = TRUE, echo = FALSE, fig.height= 3, fig.width=6, fig.cap = "Difference-in-difference comparison for control and treated groups for (A) individual extraction as number of fish, (B) as proportion of available stock size, and (C) cooperation.", fig.pos = "H", out.extra= '', fig.align='center'}


# ## Visualization based on model
# g1 <- diff_df[1:4,] %>% select(1:3) %>%
#   gather(key = time, value = estimate, before, after) %>%
#   mutate(time = as_factor(time)) %>%
#   ggplot(aes(time, estimate)) +
#   geom_point(aes(color = treatment), show.legend = FALSE) +
#   geom_line(aes(group = treatment, color = treatment)) + 
#   labs(tag = "A") +
#   theme_light(base_size = 6) + theme( legend.position = "right")
# 
# 
# ## Visualization based on model
# g2 <- diff_df2[1:4,] %>% select(1:3) %>%
#   gather(key = time, value = estimate, before, after) %>%
#   mutate(time = as_factor(time)) %>%
#   ggplot(aes(time, estimate)) +
#   geom_point(aes(color = treatment)) +
#   geom_line(aes(group = treatment, color = treatment)) +
#   labs(tag = "B") +
#   theme_light(base_size = 6) + theme( legend.position = "bottom")
# 
# ## Visualization based on model
# g3 <- diff_df3[1:4,] %>% select(1:3) %>%
#   gather(key = time, value = estimate, before, after) %>%
#   mutate(time = as_factor(time)) %>%
#   ggplot(aes(time, estimate)) +
#   geom_point(aes(color = treatment), show.legend = FALSE) +
#   geom_line(aes(group = treatment, color = treatment)) +
#   labs(tag = "C") +
#   theme_light(base_size = 6) + theme( legend.position = "right")
# 

# source('~/Dropbox/Code/multiplot.R')
# g <- list (g1,g2, g3)
# 
# layout <- matrix(c(1:3), ncol = 3, nrow = 1, byrow = T)
# multiplot(plotlist = g, layout = layout)

```

```{r alternative, include = TRUE, echo = FALSE, fig.height= 4, fig.width=6, fig.cap = "Difference-in-difference comparison for control and treated groups for (A) individual extraction as number of fish, (B) as proportion of available stock size, and (C) cooperation.", fig.pos = "h", out.extra= '', fig.align='center', warning=FALSE, message=FALSE}


diff_df$response <- "individual extraction"
diff_df <- diff_df %>%
  mutate(type = ifelse(
    str_detect(treatment, "-Baseline"), "first_difference", 
    ifelse(str_detect(treatment, "-counter"), "counterfactual", "observed"))) %>%
  mutate(treatment = str_remove(treatment, "-Baseline"),
         treatment = str_remove(treatment, "-counter")) %>%
    gather(key = time, value = estimate, before, after) %>%
  mutate(time = as_factor(time), type = as_factor(type), treatment = as_factor(treatment)) %>%
  filter(type != "first_difference")

diff_df2$response <- "proportion stock"
diff_df2 <- diff_df2 %>%
  mutate(type = ifelse(
    str_detect(treatment, "-Baseline"), "first_difference", 
    ifelse(str_detect(treatment, "-counter"), "counterfactual", "observed"))) %>%
  mutate(treatment = str_remove(treatment, "-Baseline"),
         treatment = str_remove(treatment, "-counter")) %>%
    gather(key = time, value = estimate, before, after) %>%
  mutate(time = as_factor(time), type = as_factor(type), treatment = as_factor(treatment)) %>%
  filter(type != "first_difference")
  

diff_df3$response <- "cooperation"
diff_df3 <- diff_df3 %>%
  mutate(type = ifelse(
    str_detect(treatment, "-Baseline"), "first_difference", 
    ifelse(str_detect(treatment, "-counter"), "counterfactual", "observed"))) %>%
  mutate(treatment = str_remove(treatment, "-Baseline"),
         treatment = str_remove(treatment, "-counter")) %>%
    gather(key = time, value = estimate, before, after) %>%
  mutate(time = as_factor(time), type = as_factor(type), treatment = as_factor(treatment)) %>%
  filter(type != "first_difference")
  
  
diff_df4 <- bind_rows(
  diff_df, diff_df2, diff_df3) %>%
  mutate(response = as_factor(response),
         response = fct_relevel(response, "individual extraction", "proportion stock", "cooperation")) # j190929: this stopped working, the ordering of factors

g_diff <- diff_df4  %>% 
  ggplot(aes(time, estimate, group = type)) +
  geom_point() +
  geom_line(aes(linetype = type)) +
  facet_grid(response ~ treatment, scales = "free_y" ) +
  theme_light(base_size = 6) + theme(legend.position = "bottom") +
  labs()

# ggsave(g_diff, filename = "diff-in-diff.png", device = "png", width = 4, height = 4, units = "in", dpi = 600 )

g_diff
```




Notice that in our table of treatment effects, the difference `after-before` produces the interaction effects $\hat{\tau}$ from the equation above as expected. See Tables 4 and 5 which show the different regression results and compare them with Tables 2 and 3 respectively, which are calculated following the formulas of Table 1.


```{r table0, results='asis', include=TRUE, echo=FALSE}
stargazer::stargazer(
  # clustered and robust:
  coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  # clustered and robust:
  coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC2", cluster = "group")),
  # clustered and robust:
  coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC3", cluster = "group")),
  # clustered and robust:
  coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC4", cluster = "group")),
  # last model with NW and HC4, more strict
  coeftest(p4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")),
  type = "latex", multicolumn = FALSE, header = FALSE, intercept.bottom = FALSE, 
  model.names= FALSE, font.size = "small", digits = 2, 
  float = TRUE, no.space = TRUE, single.row = FALSE, align = TRUE,
  dep.var.caption = "", dep.var.labels.include = FALSE, df = FALSE,
  title = "Clustered and robust standard errors estimation with White method and (1) HC1, (2) HC2, (3) HC3, (4) HC4 weighting schemes, and (5) Newey and West method with HC4 scheme. The response variable is individual extraction."
  )

```

```{r table01, results='asis', include=TRUE, echo=FALSE}
stargazer::stargazer(
  # clustered and robust:
  coeftest(q4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  # clustered and robust:
  coeftest(q4, vcov.=function(x) vcovHC(x, method="white2", type="HC2", cluster = "group")),
  # clustered and robust:
  coeftest(q4, vcov.=function(x) vcovHC(x, method="white2", type="HC3", cluster = "group")),
  # clustered and robust:
  coeftest(q4, vcov.=function(x) vcovHC(x, method="white2", type="HC4", cluster = "group")),
  # last model with NW and HC4, more strict
  coeftest(q4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")),
  type = "latex", multicolumn = FALSE, header = FALSE, intercept.bottom = FALSE, 
  model.names= FALSE, font.size = "small", digits = 2, 
  float = TRUE, no.space = TRUE, single.row = FALSE, align = TRUE,
  dep.var.caption = "", dep.var.labels.include = FALSE, df = FALSE,
  title = "Clustered and robust standard errors estimation with White method and (1) HC1, (2) HC2, (3) HC3, (4) HC4 weighting schemes, and (5) Newey and West method with HC4 scheme. The response variable is individual extraction as proportion of the available stock."
  )

```






```{r table1, results='asis', include=TRUE, echo=FALSE}
stargazer::stargazer(
  p1,
  # robust: # I think white1 and HC1 are stata defaults
  coeftest(p1, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  #clustered and robust
  coeftest(p2, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  p3,
  # robust:
  coeftest(p3, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  # clustered and robust:
  coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  p5,
  # robust:
  coeftest(p5, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  # clustered and robust:
  coeftest(p6, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  # last model with NW and HC4, more strict
  coeftest(p4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")),
  type = "latex", multicolumn = FALSE, header = FALSE, intercept.bottom = FALSE, 
  model.names= FALSE, font.size = "tiny", digits = 2, 
  float = TRUE, no.space = TRUE, single.row = FALSE, align = TRUE,
  dep.var.caption = "", dep.var.labels.include = FALSE, df = FALSE, float.env = "sidewaystable",
  title = "Comparison of models 1-10 with response variable individual extraction."
)
```


```{r table2, results='asis', warning=FALSE, message=FALSE, include = TRUE, echo = FALSE}
stargazer::stargazer(
  q1,
  # robust: # I think white1 and HC1 are stata defaults
  coeftest(q1, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  #clustered and robust
  coeftest(q2, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  q3,
  # robust:
  coeftest(q3, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  # clustered and robust:
  coeftest(q4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  q5,
  # robust:
  coeftest(q5, vcov.=function(x) vcovHC(x, method="white1", type="HC1")),
  # clustered and robust:
  coeftest(q6, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group")),
  # last model with NW and HC4, more strict
  coeftest(q4, vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")),
  type = "latex", font.size = "tiny", model.names = FALSE, 
  multicolumn = FALSE, header = FALSE, intercept.bottom = FALSE, digits = 2,
  float = TRUE, no.space = TRUE, single.row = FALSE, df = FALSE, align = TRUE,
  dep.var.caption = "", dep.var.labels.include = FALSE, float.env = "sidewaystable",
  title = "Model comparison 1-10 with response variable individual extraction as proportion of available stock."
)
```

Jorge also asked me to perform F-tests or linear hypotheses to check that the coefficients in the regression are significantly different. If I understood correctly, the test is to check that the difference between `Treatment*part` and `Treatment` coefficients are indeed different from zero. Going back to our regression formula, I'm testing if $H_0: \hat{\gamma}+\hat{\tau} = 0$, or if the difference of the `Treated-Control` is significantly different from zero. Alternatively, I'm also adding an F-test that check whether all coefficients from our regressions are different from zero. All F-tests use a robust estimation of standard errors using variance-covariance matri of type "HC4" clustered around group, a more restricted version that the default STATA option developed by Newey-West. Results are shown in Tables 8, 9, and 10. The F-statistic estimated is for the joint hypothesis that $H_0: \hat{\gamma}+\hat{\tau} = 0$ for all treatments, so the alternative model has 3 degrees of freedom, one for each treatment tested. 

```{r f_test1,  results='asis', warning=FALSE, message=FALSE, include = TRUE, echo = FALSE}
hyp <- c("TreatmentThreshold:partTRUE + TreatmentThreshold = 0",
         "TreatmentRisk:partTRUE + TreatmentRisk = 0",
         "TreatmentUncertainty:partTRUE + TreatmentUncertainty= 0")

lh1 <- linearHypothesis(p4, hyp, test = "F", 
                  vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")) %>%
  tidy() %>% as.data.frame()

lh2 <- linearHypothesis(q4, hyp, test = "F", 
                 vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")) %>%
  tidy() %>% as.data.frame()

lh4 <- linearHypothesis(c4, hyp, test = "F", 
                 vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")) %>%
  tidy() %>% as.data.frame()

lh3 <- linearHypothesis(p4, diag(10), c(rep(0,10)), test = "F",
                 vcov.=function(x) vcovNW(x,  type="HC4", cluster = "group")) %>%
  tidy() %>% as.data.frame()

stargazer::stargazer(
  lh1, type = "latex", digits = 2, digits.extra = 1,summary = FALSE, header = FALSE,
  title = "F-test linear hypothesis with individual extraction model")
stargazer::stargazer(
  lh2, type = "latex", digits = 2, digits.extra = 1, summary = FALSE, header = FALSE,
  title = "F-test linear hypotehsis with proportion extraction model")
stargazer::stargazer(
  lh3, type = "latex", digits = 2, digits.extra = 1,summary = FALSE, header = FALSE,
  title = "Testing that all coefficients are different from zero with individual extraction model")

```



## Final regression for the paper

I will then go with `p4` and `q4` or models 6 and 10 in the long tables (6 and 7). These are models that are clusterd around 3 dimensions (individual, group, and time) and shown consistent results under different clustering techniques ("HC1" to "HC4" and Newey and West variation). In addition to the panel regressions, I will run OLS regressions on summary statistics for the second part of the game. Why don't use the first one? Well, because there is noise on the first part when participants were still learning the game and getting use to the group dynamics. I was also discouraged of using survey data as covariants in the panel regression. In the diff-in-diff approach, the survey covariants are not time-variant and introduce noise in the interpretation of diff-in-diff coefficients.

```{r fig5, include = TRUE, echo = FALSE, fig.height=4, fig.width=4, fig.align='center', warning=FALSE, message=FALSE, dev.args= list(pointsize = 6), fig.cap = "Correlations between response variables"}

pm <- GGally::ggpairs(
  data = ind_coop %>% filter(part == TRUE) %>%
    rename(
      `mean extraction` = mean_extraction,
      `mean % extraction` = mean_prop_extr,
      `variance extraction` = var_extraction,
      `variance % extraction` = var_prop_extr,
      `median cooperation` = med_coop
    ),
  columns = c(3:6,14,52),
  aes(color = Treatment, fill = Treatment),
  upper = list(continuous = wrap("cor", size = 2, alignPercent = 0.95, hjust = 0.1)),
  diag = list(continuous = wrap("densityDiag", size =0.4, alpha = 0.25)),
  lower = list(continuous = wrap("points", size = 0.5))
  )

pm <- pm + theme_light(base_size = 6) + theme(legend.position = "bottom")

# ggsave(pm, filename = "correlations.pdf", device = "pdf", width = 4, height = 4, units = "in", dpi = 600 )

pm

# quartz(width = 5, height = 5, pointsize = 6)
# 
# quartz.save(file = "correlations.pdf", type = "pdf", width = 5, height = 5, pointsize = 6, dpi = 600)
```

```{r correlations_reg, include = TRUE, echo = FALSE, fig.height=4, fig.width=4, fig.align='center', warning=FALSE, message=FALSE, dev.args= list(pointsize = 6), fig.cap = "Correlations between explanatory variables"}
pm2 <- GGally::ggpairs(
  data = ind_coop %>% filter(part == TRUE) %>%
    rename(
      `Education [years]` = education_yr,
      `Risk aversion` = Risk,
      `Ambiguity aversion` = Amb,
      `Proportion of agreements` = prop_ag,
      `How often do you have bad days?` = BD_how_often,
      `Expect children to fish` = fishing_children
    ),
  columns = c(8, 37, 44, 48, 53,54, 57,58),
  aes(color = Place, fill = Place),
  upper = list(continuous = wrap("cor", size = 1, alignPercent = 0.95, hjust = 0.1)),
  diag = list(continuous = wrap("densityDiag", size =0.4, alpha = 0.25)),
  lower = list(continuous = wrap("points", size = 0.5))
  )

pm2 <- pm2 + theme_light(base_size = 5) + theme(legend.position = "bottom")

# ggsave(pm2, filename = "correlations2.pdf", device = "pdf", width = 5, height = 5, units = "in", dpi = 600 )

pm2

# quartz(width = 5, height = 5, pointsize = 6)
# 
# quartz.save(file = "correlations2.pdf", type = "pdf", width = 5, height = 5, pointsize = 6, dpi = 600)
```



### OLS with survey covariants and ambiguity / risk tasks.

* Socio economic variables:
    + *age*: age in years (`r sum(is.na(ind_coop$age))` missing values).
    + *fishing_age*: age at which the person started fishing (`r sum(is.na(ind_coop$fishing_age))` missing values).
    + *sale*: How much of the catch is for sale? (0 = none : 4 = all, `r sum(is.na(ind_coop$sale))` missing values).
    + *take_home*: How much of the catch is for take home? (0 = none : 4 = all, `r sum(is.na(ind_coop$take_home))` missing values).
    + *life_satisfaction*: Self assessment of life satisfaction where 1 is very satisfied and 4 very dissatisfied (`r sum(is.na(ind_coop$life_satisfaction))` missing values).
    + *education*: Formal education (1=none, 2=elementary, 3=secondary, 4=university, `r sum(is.na(ind_coop$education_yr))` mising values )
* Fishing variables:
    + *ND_log_pesos*: normal day earning in pesos (log scale, `r sum(is.na(ind_coop$ND_pesos))` missing values).
    + *BD_log_pesos*: Bad day earning in pesos (in log scale, added 1 to 0 to avoid -Inf values, `r sum(is.na(ind_coop$age))` missing values).
    + *week_days*: Number of fishing days in a normal week (`r sum(is.na(ind_coop$week_days))` missing values).
    + *ND_hours*: Number of hours per day in a normal day (`r sum(is.na(ind_coop$ND_hrs))` missing values).
    + *BD_how_often*: How often do you have a bad day? (once a year = 1, once a month = 2, once a week = 3, > once a week = 4, `r sum(is.na(ind_coop$BD_how_often))` missing values)
    + *group_fishing*: Is fishing done in groups (1 = yes, 0 = no, `r sum(is.na(ind_coop$group_fishing))` missing values)
    + *boat*: Do you own the boat? yes =1, no = 0 (`r sum(is.na(ind_coop$boat))` missing values).
    + *sharing_art*: Do you share your fishing gear? yes = 1, no = 0 (`r sum(is.na(ind_coop$sharing_art))` missing values).
    + *fishing_children*: Do you expect your children to become fishermen (0=definitely no, 1=no, 2=definitely yes, 3=yes, 4=don't know, `r sum(is.na(ind_coop$fishing_children))` missing values)
    + *history_rs*: Have you experience dramatic changes (regime shifts)? yes = 1, no = 0 (`r sum(is.na(ind_coop$history_rs))` missing values).
* Risk and ambiguity task:
    + *Risk*: Risk elicitation task where 1 is risk-taker and 6 risk-averse (`r sum(is.na(ind_coop$Risk))` missing values).
    + *Amb*: Ambiguity elicitation task where 1 is ambiguity-taker, and 6 ambiguity-averse (`r sum(is.na(ind_coop$Amb))` missing values).

```{r regression_survey, include = TRUE, echo = FALSE, message=FALSE, warning=FALSE}
y_vars <- c("mean_extraction", "mean_prop_extr", "med_coop", "variance", "coordination", "var_extraction", "var_prop_extr")
x_vars <- "Treatment + age + education_yr + BD_how_often + fishing_children  + Risk + Amb  + prop_ag"
out <-  map2(x_vars, y_vars, 
         ~ lm_robust(as.formula(paste(.y, "~", .x)),
              data = ind_coop %>% filter(part == T) %>% ungroup(),
              se_type = 'stata', cluster = group)
  )
  
  
# out %>%
#   map(., summary) %>%
#   map(.,"r.squared")

g_reg2 <- out %>%
  map(tidy) %>%
  map2(., .y = y_vars , function(x,y) {x$model <- y; return(x)}) %>%
  bind_rows() %>% #pull(model) %>% unique()
  mutate( # correct the names of terms
    term = str_replace_all(string = term, pattern = "\\(Intercept\\)", replacement = "Intercept"),
    term = str_replace_all(string = term, pattern = "age", replacement = "Age [years]"),
    term = str_replace_all(string = term, pattern = "education_yr", replacement = "Education [years]"),
    term = str_replace_all(string = term, pattern = "BD_how_often",
                           replacement = "How often do you have bad days?\n [1:yearly - 4:daily]"),
    term = str_replace_all(term, "^Risk", "Risk aversion"),
    term = str_replace_all(term, "Amb", "Ambiguity aversion"),
    term = str_replace_all(term, "prop_ag", "% rounds with agreements"),
    term = str_replace_all(term, "fishing_children", "Do you expect your children to fish?\n[0:No, 1:Yes]") 
    ## correct on data and regressions
  ) %>%
  mutate(
    model = str_replace_all(model, "mean_extraction", "mean extraction"),
    model = str_replace_all(model, "mean_prop_extr", "mean %\n extraction"),
    model = str_replace_all(model, "med_coop", "median\n cooperation"),
    model = str_replace_all(model, "variance", "variance\n cooperation"),
    model = str_replace_all(model, "var_extraction", "variance\n extraction"),
    model = str_replace_all(model, "var_prop_extr", "variance %\n extraction"),
    model = factor(model, levels = 
                     c("mean extraction", "mean %\n extraction", "variance\n extraction", "variance %\n extraction",
                      "median\n cooperation", "variance\n cooperation", "coordination"))
  ) %>%
  mutate(
    var_type = ifelse(
      str_detect(term, "Treatment"), "Treatment",
      ifelse(
        str_detect(term, "Place"), "Place",
             ifelse(
               str_detect(term, "Intercept"), ".", "Socio-economic aspects")))
  ) %>% # pull(var_type) %>% unique()
  mutate(
    term = str_remove(term, "Treatment"),
    term = str_remove(term, "Place"),
    var_type = factor(var_type, levels = c("." ,"Treatment", "Place", "Socio-economic aspects") )
  ) %>%
  
  mutate(term = factor(term, levels = rev(unique(term)))) %>%
  mutate(conf.high = estimate + std.error,
         conf.low = estimate - std.error,) %>%
  ggplot(aes(x = estimate, y = term)) +
  geom_vline(xintercept = 0, color = "grey84", linetype = 2, size = 0.5) +
    geom_point(aes(shape = ifelse(
        p.value < 0.05, "< 0.05" ,
            ifelse(p.value < 0.1, "< 0.1", "> 0.1")
        )), size = 2, show.legend = TRUE) +
    scale_shape_manual(name = "p value", values = c(19,7,1)) +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high, height = .25), size = 0.3) +
  scale_x_continuous(minor_breaks = NULL, breaks = scales::pretty_breaks(n=3)) +
  theme_light(base_size = 7) + 
  theme(legend.position = "bottom", axis.title.y = element_blank(), axis.text.x = element_text(size = 5) ) +
  facet_grid(var_type ~ model, scales = "free", switch = "y", space = "free_y") 
  #ggtitle("What does explain the behaviour of individuals?") #subtitle = "Robust estimation with standard errors HC1 (aka. Stata) and clustered around groups"


# ggsave(g_reg2, filename = "fig3_regression_cooperation.png", device = "png", width = 6, height = 4, units = "in", dpi = 600 )
g_reg2

# quartz(width = 6, height = 4, pointsize = 6)
# g_reg2
# quartz.save(file = "fig3_regression_cooperation.pdf", type = "pdf", width = 6, height = 4, pointsize = 6, dpi = 600, bg = "white")

```


or in table form if you prefer:

```{r table3, results='asis', warning=FALSE, message=FALSE, include = TRUE, echo = FALSE}

out <-  map2(x_vars, y_vars, 
         ~ lm(as.formula(paste(.y, "~", .x)),
              data = ind_coop %>% filter(part == T) %>% ungroup()
              )
  )

stargazer::stargazer(
  out,
  type = "latex", font.size = "small", model.names = FALSE,
  multicolumn = FALSE, header = FALSE, intercept.bottom = FALSE, digits = 2,
  float = TRUE, no.space = TRUE, single.row = FALSE, df = FALSE, align = TRUE,
  dep.var.labels = NULL, #c("mean_extraction", "mean_prop_extr", "med_coop", "variance", "coordination"),
  dep.var.labels.include = FALSE,
  title = "Model comparison between (1) mean extraction, (2) mean proportion of stock available extracted, (3) median cooperation, (4) cooperation variance, and (5) coordination."
)

```

### Figure 2:

```{r fig2, include = TRUE, echo = FALSE, fig.height=6, fig.width=7, fig.align='center', warning=FALSE, message=FALSE, dev.args= list(pointsize = 8), fig.cap = "What drives the behavior of individuals."}

# ind_coop %>% ungroup() %>%
#   filter(part == TRUE) %>%
#   select(Treatment, med_coop, coordination) %>%
#   ggpairs(columns = c(2,3),
#     aes(color = Treatment, alpha = 0.5),
#     upper = list(continuous = wrap("points", size = 0.5, alpha = 0.7)),
#   lower = list(continuous = wrap("cor", size = 3, alignPercent = 1, hjust = 0))
#   )


g1 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, med_coop, coordination) %>%
  ggplot(aes(coordination)) + 
  geom_density(aes(color = Treatment, fill = Treatment), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Treatment), 
               alpha = 0.4, sides = "r",
               show.legend = FALSE,
           length = unit(0.05, "npc")) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") +
  coord_flip() + scale_y_reverse() + labs(tag = "A") +
  theme_light(base_size = 8) + theme(axis.title.y = element_blank())

g3 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, med_coop, coordination) %>%
  ggplot(aes(med_coop)) + 
  geom_density(aes(color = Treatment, fill = Treatment), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Treatment), 
               alpha = 0.4, sides = "t",
               show.legend = FALSE,
           length = unit(0.05, "npc")) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") +
  scale_y_reverse() +
  theme_light(base_size = 8) + theme(axis.title.x = element_blank())

g2 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, med_coop, coordination) %>%
  ggplot(aes( med_coop, coordination)) + 
  # geom_rect(aes(xmin = 0, xmax = max(coordination)+0.1, ymin = 0, ymax = 1),
  #           fill = "skyblue", alpha = , color = "skyblue") +
  geom_vline(xintercept = 1, color = "orange") +
  geom_point(aes(color = Treatment), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  geom_text(
    data = data.frame(
      x = c(0.5, 1.5),
      y = c(.2, .2), 
      text = c("cooperators", "defectors"),
      color = c("blue", "red")),
    aes(x = x,y = y,label = text),
    color = c("blue", "red"), size = 3,
    show.legend = FALSE) + 
  xlab("median cooperation") + 
  theme_light(base_size = 8)

library(ggpubr)

leg <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, med_coop, coordination) %>%
  ggplot(aes(med_coop)) + 
  geom_density(aes(color = Treatment, fill = Treatment), 
               alpha = 0.4, 
               show.legend = TRUE) + 
  geom_rug(aes(color = Treatment), 
               alpha = 0.4, sides = "r",
               show.legend = TRUE) +
  coord_flip() + scale_y_reverse() + 
  theme_light(base_size = 8) +
  theme(legend.position = "bottom")

legend <- leg %>%
  get_legend() %>%
  as_ggplot()

g5 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, mean_prop_extr) %>%
  ggplot(aes(mean_prop_extr)) + 
  geom_density(aes(color = Treatment, fill = Treatment), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Treatment), 
               alpha = 0.4, sides = "r",
               show.legend = FALSE) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") + #xlab("mean % extraction") +
  coord_flip() + scale_y_reverse() + labs(tag = "B") +
  theme_light(base_size = 8) + theme(axis.title.y = element_blank())

g6 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, mean_extraction) %>%
  ggplot(aes(mean_extraction)) + 
  geom_density(aes(color = Treatment, fill = Treatment), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Treatment), 
               alpha = 0.4, sides = "t",
               show.legend = FALSE) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") + #xlab("mean extraction") +
  scale_y_reverse() +
  theme_light(base_size = 8) + theme(axis.title.x = element_blank())

g7 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, mean_extraction, mean_prop_extr) %>%
  ggplot(aes( mean_extraction, mean_prop_extr)) + 
  geom_point(aes(color = Treatment), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("mean extraction") + ylab("mean % extraction") +
  theme_light(base_size = 7)

g8 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, var_extraction, var_prop_extr) %>%
  ggplot(aes( var_extraction, var_prop_extr)) + 
  geom_point(aes(color = Treatment), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("variance extraction") + ylab("variance % extraction") +
  theme_light(base_size = 7)

g9 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Treatment, variance, coordination) %>%
  ggplot(aes( variance, coordination)) + 
  geom_point(aes(color = Treatment), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("variance cooperation") + ylab("coordination") +
  theme_light(base_size = 7)

source('~/Dropbox/Code/multiplot.R')

#g <- list(g1, g2, g5, g7, legend, g3,  legend, g6, g_reg2)
g <- list(g1, g2, g5, g7, g9, g3, g8, g6, legend)
layout <- matrix(data = c(1,2,2,3,4,4,
                          1,2,2,3,4,4,
                          5,6,6,7,8,8,
                          9,9,9,9,9,9),
                 nrow = 4, ncol = 6, byrow = TRUE)


# quartz(width = 7, height = 6, pointsize = 8)
# multiplot(plotlist = g, layout = matrix(c(1:8, rep(9,8)), 4,4, byrow = TRUE))
multiplot(plotlist = g, layout = layout)
# quartz.save(file="fig2_response_variables.png", type = "png", width = 7, height = 6, pointsize = 8, dpi = 600, bg= "white")

# ggsave( filename = "fig2_model.png", device = "png", width = 7, height = 7, units = "in", dpi = 600 )

```


```{r fig2_place, include = TRUE, echo = FALSE, fig.height=6, fig.width=7, fig.align='center', warning=FALSE, message=FALSE, dev.args= list(pointsize = 8), fig.cap = "What drives the behavior of individuals."}

# ind_coop %>% ungroup() %>%
#   filter(part == TRUE) %>%
#   select(Treatment, med_coop, coordination) %>%
#   ggpairs(columns = c(2,3),
#     aes(color = Treatment, alpha = 0.5),
#     upper = list(continuous = wrap("points", size = 0.5, alpha = 0.7)),
#   lower = list(continuous = wrap("cor", size = 3, alignPercent = 1, hjust = 0))
#   )


g1 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, med_coop, coordination) %>%
  ggplot(aes(coordination)) + 
  geom_density(aes(color = Place, fill = Place), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Place), 
               alpha = 0.4, sides = "r",
               show.legend = FALSE,
           length = unit(0.05, "npc")) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") +
  coord_flip() + scale_y_reverse() + labs(tag = "A") +
  theme_light(base_size = 8) + theme(axis.title.y = element_blank())

g3 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, med_coop, coordination) %>%
  ggplot(aes(med_coop)) + 
  geom_density(aes(color = Place, fill = Place), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Place), 
               alpha = 0.4, sides = "t",
               show.legend = FALSE,
           length = unit(0.05, "npc")) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") +
  scale_y_reverse() +
  theme_light(base_size = 8) + theme(axis.title.x = element_blank())

g2 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, med_coop, coordination) %>%
  ggplot(aes( med_coop, coordination)) + 
  # geom_rect(aes(xmin = 0, xmax = max(coordination)+0.1, ymin = 0, ymax = 1),
  #           fill = "skyblue", alpha = , color = "skyblue") +
  geom_vline(xintercept = 1, color = "orange") +
  geom_point(aes(color = Place), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  geom_text(
    data = data.frame(
      x = c(0.5, 1.5),
      y = c(.2, .2), 
      text = c("cooperators", "defectors"),
      color = c("blue", "red")),
    aes(x = x,y = y,label = text),
    color = c("blue", "red"), size = 3,
    show.legend = FALSE) + 
  xlab("median cooperation") + 
  theme_light(base_size = 8)

library(ggpubr)

leg <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, med_coop, coordination) %>%
  ggplot(aes(med_coop)) + 
  geom_density(aes(color = Place, fill = Place), 
               alpha = 0.4, 
               show.legend = TRUE) + 
  geom_rug(aes(color = Place), 
               alpha = 0.4, sides = "r",
               show.legend = TRUE) +
  coord_flip() + scale_y_reverse() + 
  theme_light(base_size = 8) +
  theme(legend.position = "bottom")

legend <- leg %>%
  get_legend() %>%
  as_ggplot()

g5 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, mean_prop_extr) %>%
  ggplot(aes(mean_prop_extr)) + 
  geom_density(aes(color = Place, fill = Place), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Place), 
               alpha = 0.4, sides = "r",
               show.legend = FALSE) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") + #xlab("mean % extraction") +
  coord_flip() + scale_y_reverse() + labs(tag = "B") +
  theme_light(base_size = 8) + theme(axis.title.y = element_blank())

g6 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, mean_extraction) %>%
  ggplot(aes(mean_extraction)) + 
  geom_density(aes(color = Place, fill = Place), 
               alpha = 0.4, 
               show.legend = FALSE) + 
  geom_rug(aes(color = Place), 
               alpha = 0.4, sides = "t",
               show.legend = FALSE) +
  xlab("") + ylab("") + scale_x_continuous(position = "top") + #xlab("mean extraction") +
  scale_y_reverse() +
  theme_light(base_size = 8) + theme(axis.title.x = element_blank())

g7 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, mean_extraction, mean_prop_extr) %>%
  ggplot(aes( mean_extraction, mean_prop_extr)) + 
  geom_point(aes(color = Place), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("mean extraction") + ylab("mean % extraction") +
  theme_light(base_size = 7)

g8 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, var_extraction, var_prop_extr) %>%
  ggplot(aes( var_extraction, var_prop_extr)) + 
  geom_point(aes(color = Place), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("variance extraction") + ylab("variance % extraction") +
  theme_light(base_size = 7)

g9 <- ind_coop %>% ungroup() %>%
  filter(part == TRUE) %>%
  dplyr::select(Place, variance, coordination) %>%
  ggplot(aes( variance, coordination)) + 
  geom_point(aes(color = Place), size = 1, 
               alpha = 0.7, 
               show.legend = FALSE) + 
  xlab("variance cooperation") + ylab("coordination") +
  theme_light(base_size = 7)

source('~/Dropbox/Code/multiplot.R')

#g <- list(g1, g2, g5, g7, legend, g3,  legend, g6, g_reg2)
g <- list(g1, g2, g5, g7, g9, g3, g8, g6, legend)
layout <- matrix(data = c(1,2,2,3,4,4,
                          1,2,2,3,4,4,
                          5,6,6,7,8,8,
                          9,9,9,9,9,9),
                 nrow = 4, ncol = 6, byrow = TRUE)


# quartz(width = 7, height = 6, pointsize = 8)
# multiplot(plotlist = g, layout = matrix(c(1:8, rep(9,8)), 4,4, byrow = TRUE))
multiplot(plotlist = g, layout = layout)
# quartz.save(file="fig2_response_variables.png", type = "png", width = 7, height = 6, pointsize = 8, dpi = 600, bg= "white")

# ggsave( filename = "fig2_model.png", device = "png", width = 7, height = 7, units = "in", dpi = 600 )

```












Save work in an R object that can be loaded and used in paper

```{r}
# save.image(file = "Regressions_paper2_200527.RData", safe = TRUE)
```





### Structural equation model

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(lavaan)
library(piecewiseSEM)
library(nlme)

hyp <- "
cooperation2 ~ optimal + ind_extraction + Treatment
ind_extraction ~ Treatment
"
dat <- dat %>% mutate(
  Treatment = ordered(Treatment))


dat <- dat %>%
  mutate(
    Treatment_order = ifelse(
      Treatment == "Base line", 0,
      ifelse(Treatment == "Threshold", 1,
             ifelse(Treatment == "Risk", 2, 3))
    )
  )

sem1 <- psem(
  lme(cooperation2 ~ optimal + ind_extraction + Treatment_order, random  = ~1|group/ID_player,
      na.action = na.omit,
      data = filter(dat, Round > 6)),
  lme(ind_extraction ~ Treatment_order, random = ~1|group/ID_player,
      na.action = na.omit,
      data = filter(dat, Round > 6)),
  "ind_extraction %~~% optimal",
  data = dat %>% filter(Round > 6) %>% as.data.frame())

summary(sem1)

```

### Some tests for panel data:

Fixed or random? The Haussman test below suggest a fixed effects model when using individual extraction as response variable, it does suggest random effect (p>0.05) for cooperation and proportion of stock. However, the nested structure to control for 3D: individual, group, time, is not possible to implement in fixed effects version. The rest of the analysis is done with random effects.
```{r}
fixed <- plm(
  prop ~ Treatment + part +Treatment * part + as.numeric(Round) , 
  data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
  model = "within"
)
p4 <- plm(
  prop ~ Treatment + part +Treatment * part + as.numeric(Round), 
  data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
  model = "random", random.method = "walhus",
  effect = "nested" )

phtest(fixed, p4)
# coeftest(p4, vcov.=function(x) vcovHC(x, method="white2", type="HC1", cluster = "group"))
```

### Breusch-Pagan Lagrange multiplier (LM)
The Lagrange multiplier helps decide between random effects regression or a simple OLS regression. The null hypothesis is that variances across entitites is zero, thus no significant difference across units (no panel effect). If p<0.05 a random model is preferred, meaning there is evidence that there is differences amongst treatments. 

```{r}

pool <- plm(
  ind_extraction ~ Treatment + part +Treatment * part + as.numeric(Round) + StockSizeBegining , 
  data = pdata.frame(dat, index = c('ID_player' ,'Round', "group")),
  model = "pooling"
)

plmtest(pool, type = 'bp')
```

### Testing for cross-sectional dependnece
The cross-sectional dependence test check if the residuals are correlated accross entities. It seems that there is cross-sectional dependence, probably the group or location effect. This test in R cannot be performed with the nested model reported in the paper. Cross-sectional dependence can lead to bias in test results (contemporaneous correlation).

```{r}
pcdtest(
  plm(
  ind_extraction ~ Treatment + part +Treatment * part + as.numeric(Round) + StockSizeBegining , 
  data = pdata.frame(dat, index = c('ID_player' ,'Round')),
  model = "random", random.method = "walhus",
  effect = "twoway" )
  , test = c('lm'))
pcdtest(
  plm(
  prop ~ Treatment + part + Treatment * part + as.numeric(Round) , 
  data = pdata.frame(dat, index = c('ID_player' ,'Round')),
  model = "random", random.method = "walhus",
  effect = "twoway" )
  , test = c("cd"))
pcdtest(
  plm(
    cooperation2 ~ Treatment + part + Treatment * part + as.numeric(Round),
    data = pdata.frame(dat, index = c('ID_player' ,'Round')),
    model = "random", random.method = "walhus",
    effect = "twoway" ), 
  test = c("cd")
)

```

### Testing for serial correlation
There is serieal correlation (p < 0.05). The null hypothesis is that residuals across entities are not correlated, here entities I believe is groups. It shouldn't be a problem in micropanels with few time steps like ours, but we have it both on the random model and the random with time effects.
```{r test4}
pbgtest(p4)
pbgtest(q4)
pbgtest(c4)
```


### Dickey-Fuller test
It checks for stochastic trends, the null hypothesis is that the series as a unit root (non-stationary). If root is present one can take the first difference of the variable. p-value is < 0.05 then there is no unit roots present. The second test fails in proportion of stock or cooperation because there is missing values (0/0) for collapsed rounds.
```{r test5, warning = FALSE}
panel.set <- plm.data (dat %>% filter(part == T) , index = c('ID_player' ,'Round') ) 
library(tseries)
adf.test (panel.set$ind_extraction, k=2)
# adf.test (panel.set$prop, k=2)
```


### Breusch-Pagan test for homoskedasticity
p < 0.05 therefore there is presence of heteroskedasticity, one can use robust covariance matrix to account for it. Both tutorials in R and STATA suggest good ways of dealing with heteroskedasticity but I will stop here. First we need to define which model are we fitting and presenting on the papers: fixed, random, with treatment + location + time effects?

```{r test6, echo = FALSE, warning= FALSE}
library(lmtest)
bptest(ind_extraction ~ Treatment + part +Treatment * part + as.numeric(Round) + StockSizeBegining ,
       data = filter (dat, part == TRUE) , studentize = F )
bptest(prop ~ Treatment + part +Treatment * part + as.numeric(Round) ,
       data = filter (dat, part == TRUE) , studentize = F )
bptest(cooperation2 ~ Treatment + part +Treatment * part + as.numeric(Round),
       data = filter (dat, part == TRUE) , studentize = F )

```
